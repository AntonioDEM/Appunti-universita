\begin{enumerate}
	\item Criterio di monotonia\\
		Sia $f(x):[a,b]\to R$, continue in $[a,b]$, è derivabile in $(a,b)$.
		Allora:
		\begin{itemize}
			\item f è crescente in $[a,b]\Leftrightarrow f^\prime(x)\geq 0
				\forall x \in [a,b]$;
			\item f è crescente in $[a,b]\Leftrightarrow f^\prime(x)\leq 0
				\forall x \in [a,b]$.
		\end{itemize}
		\paragraph{Dimostrazione}
		Sia $f^\prime (x)\geq 0 \text{ e siano } x_1,x_2\in[a,b]\text{ con }
		x_2>x_1$.\\
		Per il Teorema di Lagrange $\forall x_0\in (x_1,x_2)$:	
			\begin{center}
				$f(x_2)-f(x_1)=f^\prime(x_0)(x_2-x_1)$
			\end{center}
			ma $f^\prime(x_0)\geq 0$ e $x_2-x_1>0 \Rightarrow f(x_2)\geq f(x_1)$
		\paragraph{Viceversa} Sia $f(x)$ crescente in $[a,b]$.\\
		Allora $\forall x, x+h\in (a,b)$, si ha $\frac{f(x+h)-f(x)}{h}\geq 0$\\
		Facendo il limite per $h\to 0$ si ha
		\begin{center}
			$f^\prime(x)\geq 0$
		\end{center}
		Analoga dimostrazione per
		\begin{equation}
			\text{f è decrescente in} [a,b]\Leftrightarrow f^\prime\leq 0 \forall
			x\in [a,b]
		\end{equation}
		Analoga dimostrazione per $f$ è decrescente in $[a,b]\Leftrightarrow
		f^\prime(x)\leq 0 \forall x \in [a,b]$\\
		Si ha inoltre
		\begin{itemize}
			\item $f^\prime (x)>0\Rightarrow$ strettamente crescente
			\item $f^\prime (x)<0\Rightarrow$ strettamente decrescente
		\end{itemize}
	\item Sia $f(x):[a,b]\to R$, derivabile in (a,b).
		\begin{equation}
			\text{f è costante} \Leftrightarrow f^\prime (x)=0 \forall x\in(a,b)
		\end{equation}		
	\item Sia $x_0\in (a,b)$ e $f^\prime (x_0)=0$\\
		\textit{Se esiste un intorno destro (sinistro), in cui $f^\prime (x)>0$
		e un intorno sinistro (destro) in cui $f^\prime (x)<0$, allora $x_0$ è
		un punto di minimo (massimo) relativo}.
\end{enumerate}
\section{Teorema di Cauchy}
Siamo $f,g:[a,b]\to R$:
\begin{enumerate}
	\item \textit{f e g sono continue in $[a,b]$}
	\item \textit{f e g sono derivabili in $(a,b)$}.
\end{enumerate}
Allora se $g^\prime (x) \neq 0, \forall x \in (a,b), \exists x_0\in(a,b)$:
$\frac{f^\prime (x_0)}{g^\prime (x_0)}=\frac{f(b)-f(a)}{g(b)-g(a)}$
\subsection{Dimostrazione}
Si consideri la funzione ausiliaria
\begin{center}
	$\upvarphi(x)=f(x)-[f(a)+\frac{f(b)-f(a)}{g(b)-g(a)}-(g(b)-g(a))]$
\end{center}
Essendo $g^\prime\neq 0, \forall x \in (a,b)$, allora $g(b)\neq g(a)$. Inoltre
\begin{enumerate}
	\item $\upvarphi(x)$ è continua in $[a,b]$;
	\item $\upvarphi(x)$ è derivabile in $(a,b)$;
	\item $\upvarphi(a)=\upvarphi(b)$
\end{enumerate}
\begin{center}
	$\Rightarrow \exists x_0 \in (a,b):\upvarphi^\prime(x_0)=0$
\end{center}
Cioè
\begin{center}
	$\frac{f^\prime (x_0)}{g^\prime(x_0)}=\frac{f(b)-f(a)}{g(b)-g(a)}$
\end{center}
\section{Teorema di de l'Hopital}
$\lim_{x\to x_0}f(x)=\lim_{x\to x_0}g(x)=0$ oppure $\lim_{x\to
x_0}f(x)=\lim_{x\to x_0}f(x)=\infty$\\
Se esiste il limite $\lim_{x\to x_0}\frac{f^\prime(x)}{g^\prime(x)}=l$ finito e
limitato. Allora $\lim_{x\to x_0}\frac{f(x)}{g(x)}=\lim_{x\to
x_0}\frac{f^\prime(x)}{g^\prime(x)}$\\
\texttt{Il teorema è valido anche per $x\to x_0^+$ o $x\to x_0^-$ e per $x\to
\pm\infty$ (f e g derivabili in intervalli illimitati)}
\section{Funzioni convesse e concave}
\subsection{Definizione di funziona convessa}
Sia $f(x):[a,b]\to R$, si chiama epigrafico (\textit{o sopragrafico}) di $f$
l'insieme
\begin{center}
	$epif:=\{(x,y)\in R^2:x\in[a,b]\text{ e }y\leq f(x)\}$
\end{center}
\textit{f è convessa in $[a,b]$ se il suo epigrafico è un insieme convesso}
\paragraph{Analogamenente:} \textit{f è concava in $[a,b]$ se il suo epigrafico
è un insieme concavo}\\
Sia $f(x)$ derivabile in $[a,b]$, \textit{f è convesse in
$[a,b]\Leftrightarrow f(x)\geq f(x_0)+f^\prime(x_0)(x-x_0), \forall
x,x_0\in[a,b]$}
\begin{center}
	Cioè $\forall x_0$ il grafico di $f$ sta al di sopra della retta tangente
	ad $f(x)$ in $(x_0,f(x_0))$
\end{center}
\subsection{Definizione di funziona concave}
Sia $f(x)$ derivabile in $[a,b]$, \textit{f è concava in
$[a,b]\Leftrightarrow f(x)\leq f(x_0)+f^\prime(x_0)(x-x_0), \forall
x,x_0\in[a,b]$}
\begin{center}
	Cioè $\forall x_0$ il grafico di $f$ sta al di sopra della retta tangente
	ad $f(x)$ in $(x_0,f(x_0))$
\end{center}
\subsection{Derivata seconda}
La derivata seconda di una funzione $f(x)$ rappresenta la velocità di
variazione della pendenza del grafico di $f(x)$.
\begin{center}
	$f^{\prime\prime}(0)=\frac{1}{R}$ \textit{Curvatura del grafico di $f(x)$
	in x=0}
\end{center}
\subsection{Criterio di convessità}
Sia $f:[a,b]\to R$,
\begin{enumerate}
	\item Se f è derivabile in $(a,b)$ allora
		\begin{center}
			f è convessa (concava) $\Rightarrow$ $f^\prime(x)$ è crescente
			(decrescente)
		\end{center}
	\item Se f è derivabile due volte in $(a,b)$ allora
		\begin{center}
			f è convessa (concava) $\Rightarrow f^{\prime\prime}(x)\leq
			0(f^{\prime\prime}(x)\geq 0), \forall x \in (a,b)$
		\end{center}
\end{enumerate}
Utilizzando il segno di $f^{\prime\prime}(x)$ si può stabilire se $x_0$ è un
punto di massimo i un punto di minimo relativo per $f(x)$.\\
Sia $f(x)$ derivabile due volte con derivata continua in un intorno di
$x_0\in(a,b)$:
\begin{itemize}
	\item se $f^{\prime}(x_0)=0, f^{\prime\prime}(x)>0\Rightarrow x_0$ è punto di minimo
relativo;
\item se $f^{\prime}(x_0)=0, f^{\prime\prime}(x)<0\Rightarrow x_0$ è punto di massimo
relativo.
\end{itemize}
Infatti, supponiamo che $f^{\prime}(x_0)=0, f^{\prime\prime}(x)>0$ con
$f^{\prime\prime}$ continua. Per il Teorema della permanenza del segno:
$f^{\prime\prime}(x)>0$ in $I(x_0,\delta)\Rightarrow$ è convessa in I:
\begin{center}
	$f(x)\geq f(x_0)+f^\prime(x_0)(x-x_0)$.
\end{center}
Ma $f^\prime (x_0), \Rightarrow f(x)\Rightarrow f(x) \geq f(x_0), \forall x,
x_0\in (x_0-\delta, x_0+\delta)$ cioè $x_0$ è di minimo relativo per f.
\subsection{Criterio per i punti di massimo e di minimo relativo}
\textit{Sia $f:(a,b)\to R$, derivabile n volte in $x_0\in (a,b), n\geq 2$, tale
che in $x_0$ tutte le derivate tranne l'n-esime siano nulle. Allora:}
\begin{center}
	se n pari è $\begin{cases}
		f^{(n)}(x_0)>0 & x_0\text{ è di minimo relativo}\\
		f^{(n)}(x_0)<0 & x_0\text{ è di massimo relativo}
	\end{cases}$
\end{center}
\textit{Se n è dispari $x_0$ non è punto di estremo (\underline{si dice flesso a tangente
orizzontale})}.
\subsubsection{Definizione}
Sia $f:(a,b)\to R$ e $x_0\in (a,b)$ un punto di derivabilità per $f(x)$ oppure
$f^\prime(x_0)=\pm\infty$. \textit{$x_0$ si dice di flesso se esiste un intorno
destro di $x_0$ in cui $f$ è convessa (concava) ed un intorno sinistro in cui
$f$ è concava (convessa).}\\
Se $x_0$ è di flesso per f, ed esiste $f^{\prime\prime} (x_0),\text{ allora }
f^{\prime\prime}(x_0)=0$

\section{Punti per lo svolgimento dello studio di funzione}
Per svolgere correttamente lo studio di funzione, bisogna suddividere il tutto
in punti per svolgere correttamente lo studio in modo ordinato ed efficiente.
Se effettivamente.
\begin{enumerate}
	\item Determinazione del Campo di esistenza;
	\item Determinazione del tipo di funzione;
	\item Intersezione con gli assi;
	\item Valori agli estremi del campo di esistenza;
	\item Positività e negatività;
	\item Determinazione degli asintoti;
	\item Determinazione della derivata prima;
	\item Crescenza e decrescenza;
	\item Determinazione dei Massimi e minimi;
	\item Determinazione della derivata seconda;
	\item Determinazione della concavità, convessità e flessi;
	\item Determinazione di eventuali ulteriori punti appartenenti alla
		funzione;
	\item Grafico della funzione;
	\item Qualche esempio di studio completo di funzione.
\end{enumerate}
\subsection{Studio del grafico di f(x), Asintoti}
Se esiste una retta di equazione $y=mx+q$:
\begin{equation*}
	\lim_{x\to\infty}\{f(x)- (mx+q)\}=0
\end{equation*}
Allora $y=mx+q$ si definisce \underline{\color{red}asintoto obliquo} per f(x).
Si ha
\begin{equation*}
	m=\lim_{x\to \infty}\frac{f(x)}{x}; q=\lim_{x\to \infty} f(x)-mx
\end{equation*}

Se $\lim_{x\to \infty}f(x)=l, y=l$ si chiama asintoto orizzontale.
Se l'asintoto orizzontale non c'è (il limite sopra è infinito) allora potrebbe
esserci quello obliquo. Se $\lim_{x\to x_0}f(x)=\infty, x=x_0$ si chiama
asintoto verticale con $x_0$ punto di accumulazione per f.
\section{Approssimazione di funzioni con polinomi}
\subsection{Polinomio di Taylor}
Data una funzione $f$ derivabile $n$ volte in $x_0$, esiste uno e un solo
polinomio
\begin{equation}
	T_n(x_0)=f(x_0),T^\prime_n(x_0)=f^\prime(x_0),\dots, T^{(n)}(x_0)=f^{(n)}(x_0).
\end{equation}
Tale polinomio si chiama polinomio di Taylor ed è
\begin{equation}
	T_n(x)=f(x_0)+f^\prime(x_0)(x-x_0)+\frac{f^{\prime\prime}(x_0)}{2}(x-x_0)^2+\dots
	+ \frac{f^{\prime\prime}(x_0)}{n!}(x-x_0)^n
\end{equation}

Polinomio di centro $x_0$ e grado n
\begin{equation}
	T_n(x)=\sideset{}{^n}\sum_{k=0}\frac{f^{(b)}(x_0)(x-x_0)^k}{k!}(x-x_0)^k
\end{equation}

Se $x_0=0T_n(x)$ è detto polinomio di Mac Laurin di grado n. $R_n(x)=$ errore
che si commette quando si approssima $f(x)$ con $T_n(x)$:\\
Si ha: $R_n(x)=f(x)-T_n(x)$
\begin{itemize}
	\item $R_n(x)=o((x-x_0)^n)$ per $x\to x_0$, \underline{Formula di Peano}
		\begin{equation*}
			\text{cioè }\lim_{x\to x_0}\frac{R_n(x)}{(x-x_0)^n}=0
		\end{equation*}
	\item \textit{Se f è derivabile $n+1$ volte in $(a,b)$ ecluso al più
		$x_0$,}\\
		$\forall x\in(a,b), \exists c$ compreso tra $x$ e $x_0$:\\
		$R_n(x)=\frac{f^{(n+1)}(c)}{(n+1)!}(x-x_0)^{n+1}$ Formula di Lagrange
\end{itemize}
Esempio.
\begin{equation*}
	y=\sin x \text{ in } x=0,\text{ }T_{2n+1}(x)=\sideset{}{^n}\sum_{k=0}(-1)^k \frac{x^{2k+1}}{(2k+1)!} \text{ solo potenze dispari}
\end{equation*}
\begin{itemize}
	\item $T_1(x)=x$
	\item $T_3(x)=x-\frac{x^3}{3!}$
	\item $T_5(x)=x\frac{x^3}{3!}+\frac{x^5}{5!}$
\end{itemize}
\begin{equation*}
	\text{Analogamente in } x=0,\text{ si ottiene}
\end{equation*}
\begin{equation*}
	\ln(1+x)=x-\frac{x^2}{2}+\frac{x^3}{3}-\dots (-1)^{n+1}\frac{x^{n}}{n}+R_n(x)
\end{equation*}
\begin{equation*}
	e^x=1+x+\frac{x^2}{2}+\frac{x^3}{3!}-\dots\frac{x^{n}}{n!}+R_n(x)
\end{equation*}
\begin{equation*}
	\arctan x = x-\frac{x^3}{3}+\frac{x^5}{5}-\dots\frac{x^{2n+1}}{2n+1}+R_{2n+1}(x)
\end{equation*}

\section{Calcolo integrale per funzioni di una variabile}
\subsection{Integrale definito}
Sia $f:[a,b]\to R$, \text{limitata}
Costruiamo la somma di Cauchy-Riemann
\begin{equation*}
	S_n= \sideset{}{^n}\sum_{j=1}f(\xi_j)*(x_j-x_{j-1})=\frac{b-a}{n}\sideset{}{^n}\sum_{j=1}f(\xi_j)
\end{equation*}
Dove la suddivisione dell'intervallo $[a,b]$ è individuata dai punti $a=x_0,x_1,x_2,\dots x_{n-1},x_n=b, x_j=a+jh, h=\frac{b-a}{n}$
\subsection{Integrale definito}
la scelta dei punti $\xi_j$ è arbitraria. All'aumentare dei punti della suddivisione di $[a,b]$ aumenta il numero degli addendi della somma di Couchy-Riemann e diminuisce il valore assoluto di tali addendi.
\paragraph{Definizione}
Si dice che una funzione $f:[a,b]\to R$, limitata, è integrabile secondo Riemann in $[a,b]$, se detta $S_n$ una sua qualsiasi successione di Couchy-Riemann, esiste finito in limite di $S_n$ (per $n\to \infty$), e tale limite non dipende dalla scelta dei punti $\xi_j$. Allora si pone:
\begin{equation*}
	\lim_{n\to\infty}S_n=\int\limits^h_a=f(x)dx
\end{equation*}

Si legge <<Integrale da $a$ a $b$ in $dx$>> $f(x)$ si chiama funzione integrale e x è la variabile d'integrazione ed è una variabile muta:
\begin{center}
	$\int\limits^b_af(t)dt$ ha lo stesso significato di $\int\limits^b_af(t)dt$ 
\end{center}
\subparagraph{Variabile muta} - è una variabile che la si può nominare come meglio si crede, perché tanto il risultato è identico e quindi non ci sono vincoli nominativi.
\subsection{Integrale definito, interpretazione geometrica}
\begin{center}
	$\int\limits^b_af(x)dx, \int_If(x)dx,\int^b_af$
\end{center}
$I=[a,b]$ è dominio di integrazione, a e b sono gli estremi di integrazione.\\
Se $f(x)$ è positiva allora $\int\limits^b_a f(x)dx$ rappresenta l'aria del <<sottografico>> di f(x). Infatti la somma $S_n$ un'approssimazione dell'area del <<trapezoide T>> individuato da $f$:
\begin{equation*}
	T: \{(x,y)\in R^2: a\leq x\leq b, 0\leq y\leq f(x)\}
\end{equation*}
Se $f\geq 0\Rightarrow \int\limits_a^b f(x)dx=$ area di T\\
Se in $[a,b], f$ cambia segno allora $\int\limits^b_a f(x)dx$ è sempre un numero ma non rappresenta più l'area del sottografico di $f$.\\
Osservazione $\int^b_af(x)dx$ è un numero, non dipende da $x$. L'insieme dele funzioni integrabili secondo Riemann in $I=[a,b]$ si indica con $R(I)$ o $R([a,b])$.\\
R(I) non è vuoto, infatti ogni funzione costante $y=c$ è integrabile su qualunque intervallo $[a,b]$ e si ha
\begin{center}
	$\int^b_a c dx=c(b-a)$
\end{center}
Per qualunque suddivisione di $[a,b]$ si ha
\begin{equation*}
	S_n=\sideset{}{^n}\sum_{j=1}f(\xi_j)*(x_j-x_{j-1})=\frac{b.a}{n}\sideset{}{^n}\sum_{j=1}c=(b-a)c
\end{equation*}
\subsection{Integrale definito, classi di funzioni integrali}
\begin{enumerate}
	\item Se $f:[a,b]\to R$ è continua, allora è integrabile.
	\item Se $f:[a,b]\to R$ è Monotona e limitata, e allora è integrabile.
	\item Se $f:[a,b]\to R$ è limitata in $[a,b]$ con un numero finito di punti di discontinuità, allora è integrabile.
\end{enumerate}
Questo teorema si può estendere alle funzioni limitate con un infinità numerabile di punti di discontinuità, cioè i punti di discontinuità possono essere infiniti ma non devono essere <<troppi>>.\\
La funzione di Dirichlet su [a,b]:
\begin{equation*}
f(x)=\begin{cases}
		1 &\text{se x}\in Q \cap [a,b]\\
		0&\text{se x}\in [a,b] -Q
	\end{cases}
\end{equation*}
è limitata e non è integrabile secondo Riemann (\textit{i punti di discontinuità sono <<troppo>>: tutto $[a,b]$}) Infatti se si scelgono i punti $\xi_j$ razionali si ha
\begin{equation*}
	S_n=\sideset{}{^n}\sum_{j=1}f(\xi_j)*(x_j-x_{j-1})=\sideset{}{^n}\sum_{j=1}1*(x-x_{j-1})=(b-a)
\end{equation*} 
\subsection{Integrale definito, proprietà}
Se invece si scelgono i punti $\xi_j$ irrazionali si ha
\begin{equation*}
	S_n=\sideset{}{^n}\sum_{j=1}f(\xi_j)*(x_j-x_{j-1})=\sideset{}{^n}\sum_{j=1}0*(x-x_{j-1})=0
\end{equation*} 
\textit{Siano f e g integrabili in $[a,b]$, allora:}
\begin{enumerate}
	\item Linearità dell'integrale: se $\alpha$ e $\beta$ sono costanti la funzione $af(x)+\beta g(x)$ è integrabile e si ha
	\begin{equation*}
		\int\limits^b_a \alpha f(x)+\beta g(x)dx=\int\limits^b_a \alpha f(x)dx+\int\limits^b_a \beta g(x)dx
	\end{equation*}
	\item Addittività dell'integrale rispetto all'intervallo di integrazione: Se $a\leq s \leq b$ allora $f$ è integrabile anche su 
	$[a,s]$ e $[s,b]$ e:
	\begin{equation*}
		\int\limits^b_a f(x)dx=\int\limits^b_a f(x)dx+\int\limits^b_af(x)dx
	\end{equation*}
	\item Positività e monotonia:
	\begin{equation*}
		f\geq 0 \Rightarrow \int\limits^b_a f(x)dx\geq 0
	\end{equation*}
	\begin{equation*}
		f\geq \int\limits^b_a f(x)dx\geq \int\limits^b_a f(x)dx
	\end{equation*}
In particolare
\begin{equation*}
	| \int\limits^b_a f(x)dx |\leq \int\limits^b_a f(x)dx
\end{equation*}
\end{enumerate}
Per convenzione, se $a<b$ si pone $\int\limits^b_a f(x)dx=-\int\limits^b_a f(x)dx$
\subsection{Teorema della media integrale}
\begin{tasks}(1)
	\task Sia f limitata e integrabile secondo Riemann in [a,b].S Allora\\
	\fbox{
 		\addtolength{\linewidth}{-2\fboxsep}%
 		\addtolength{\linewidth}{-2\fboxrule}%
 		\begin{minipage}{\linewidth}
  			\begin{equation}
   				m\leq\frac{1}{b-a}\int\limits^b_a f(x)dx\leq M
  			\end{equation}
 		\end{minipage}
	}
	 \begin{equation*} \text{Dove } m=\operatorname*{\inf}_{[a,b]} f \text{ e } M=\operatorname*{sup}_{[a,b]} f\end{equation*}
	\task Se f è continua su $[a,b] \exists x_0 \in (a,b)$:\\
	\fbox{
 		\addtolength{\linewidth}{-2\fboxsep}%
 		\addtolength{\linewidth}{-2\fboxrule}%
 		\begin{minipage}{\linewidth}
  			\begin{equation}
   				\frac{1}{b-a}\int\limits^b_a f(x) dx=f(x_0)
  			\end{equation}
 		\end{minipage}
	}\\(valor medio integrale di f su [a,b])
\end{tasks}
\subsubsection{Dimostrazione}
\begin{tasks}(1)
	\task Essendo $f(x)$ limitata si ha
		\begin{equation*}
			m\leq f(x)\leq M
		\end{equation*}
		Integrando membro a membro su $[a,b]$:
		\begin{equation*}
			m\leq \frac{1}{b-a}\int\limits_a^b f(x)dx\leq M
		\end{equation*}
	\task Indichiamo con $y_0$ il valore $y_0=\frac{1}{b-a}\int\limits_a^b f(x)dx$ che è un valore compreso tra m ed M.
\end{tasks}
\textit{Essendo f continua, per il teorema dei valori intermedi, esisterà $x_0\in (a,b): f(x_0)=y_0$ cioè la tesi}
\subsection{Integrale indefinito}
Sia f continua in [a,b], allora la funzione integrale $F(x)=\int^x_af(t)dt$ è di classe $c^1([a,b])$
\begin{equation*}
	F^\prime (x)=f(x) \forall x \in [a,b]
\end{equation*}
\subsubsection{Dimostrazione}
Scriviamo il rapporto incrementale di F(x):
\begin{equation*}
	\frac{F(x+h)-F(x)}{x}=\frac{1}{h}\Bigg[\int^{x+h}_a f(t)dt-\int^{x}_a f(t)dt\Bigg]=\frac{1}{h}\Bigg[\int^{x+h}_a f(t)dt\Bigg]
\end{equation*}
\textit{Per il Teorema della media integrale applicato ad f in} $[x,x+h], \exists x (h,x+h)$:
\begin{equation*}
	\frac{1}{h}\Bigg[\int^{x+h}_a f(t)dt\Bigg]=f(x(h))
\end{equation*}
Si è ottenuto $\frac{F(x+h)-f(x)}{h}=f(x(h))$\\
Ed essendo f continua in $[a,b]$ si ha la tesi:
\begin{equation*}
	F^\prime (x)=\lim_{h\to0} \frac{F(x+h)-F(x)}{h}=\lim_{h\to 0} f(x(h))=f(x)
\end{equation*}
\paragraph{Osservazione}
L’ipotesi di continuità per f è fondamentale per la derivabilità di F. Infatti, se f è solo integrabile \underline{non} si può affermare che F è derivabile. Infatti se f è solo integrabile non si può affermare che F è derivabile. \\
Esempio
\begin{equation*}
	f(x)=segn x=\begin{cases}
		1 & x\geq 0\\
		-1 & x<0
	\end{cases}\Rightarrow F(x) =|x|
\end{equation*}
\textit{f(x) è integrabile ma non è continua, F(x) è continua ma non è derivabile in x=0.}
\paragraph{Definizione di primitiva}
Una funzione F(x), derivabile in $[a,b]$, si chiama \underline{PRIMITIVA} di f(x) se:
\begin{equation*}
	F^\prime(x)=f(x) \forall x\in [a,b]
\end{equation*}
\subparagraph{Esempio} - Una primitiva di $f(x)=\cos x$ è la funzione $F(x)=\sin x$.\\
Se $f(x)=x^2\Rightarrow F(x)=\frac{x^3}{3}$\\
Se $f(x)$ è una primitiva di f(x) lo è anche $F(x)+c$. Infatti $(F(x)+c)^\prime=F^\prime(x)=f(x)$\\
\subparagraph{Definizione} \textit{La famiglia di tutte le primitive di una funzione f(x) continua in $[a,b]$ è detta {\color{red} INTEGRALE INDEFINITO} e si indica: }$\int f(x)dx$
\subsection{Corollario del Teorema fondamentale del calcolo integrale}
\textit{Sia f (x) una funzione continua su [a,b] e G (x) una primitiva di f. Allora}
\begin{equation*}
	\int^b_a f(x)dx=G(x)-G(a)=[G(x)]^b_a = G(x)\bigg|^b_a
\end{equation*}
Esempio
\begin{equation*}
	\int^b_a x^2 dx=\frac{x^3}{3}\bigg|^b_a
\end{equation*}
\begin{equation*}
	\int^2_1 x^2dx=\frac{x^3}{3}\bigg|^2_1=\frac{2^3}{3}=\frac{1}{3}=\frac{7}{3}
\end{equation*}
\subsubsection{Dimostrazione}
Consideriamo una funzione f(t) definita in un intervallo $[c,b]$. L'area del sottografico della funzione f con $x\in [a,b]$ è dato da:
\begin{equation*}
	\int^b_a f(t)dt=\int^b_c f(t)dt-\int^a_c f(t)dt
\end{equation*}
\begin{equation*}
	\text{Ma poiché } F({\color{red} x})=\int^{{\color{red}x}}_c \text{ allora } F({\color{red} a})=\int^{{\color{red}a}}_c f(t)dt \text{ e } F({\color{red} b})=\int^{{\color{red}b}}_c f(t)dt
\end{equation*}
Per cui
\begin{equation*}
	\int^b_a f(t)dt=\int^b_c f(t)dt-\int^a_c f(t)dt= F(b)-F(a)=[F(x)]^b_a
\end{equation*}
Questo è il \underline{legame} tra l'integrale definito $\int^b_a f(x)dx$ e l'integrale indefinito $\int f(x)dx$.
\begin{itemize}
	\item $\int^b_a f(x)dx$ è un numero reale
	\item $\int^b_a f(x)dx$ è un insieme di funzioni
\end{itemize}
\subsection{Integrali indefiniti immediati}
\subsubsection{Esercizio}
\begin{equation*}
	\int\frac{\sin x}{\cos x}dx=-\int \frac{1}{\cos x} (-\sin x)dx=-\ln |\cos x| + c
\end{equation*}
\begin{itemize}
	\item $\int \sin x \cos^2 x dx=-\int-\sin x \cos^2xdx=\frac{\cos^3x}{2}+c$
	\item $\int \frac{x}{\sqrt{1+x^2}}dx=\int x (1+x^2)^{-\frac{1}{2}}dx=(1+x^2)^\frac{1}{2}+c$
	\item $\int \frac{1}{(1+x^2)\arctan x}dx=\int \frac{1}{(1+x^2)}dx=\ln(\arctan x)+c$
\end{itemize}
\subsubsection{Integrazione per parti}
Siano f e g due funzioni derivabili con derivata continua, si ha
\begin{equation*}
	\int f(x)g^\prime(x)dx=f(x)g(x)-\int f^\prime (x)g(x)dx
\end{equation*}
\textit{f(x)=fattore finito}\\
$g^\prime(x)dx=$\textit{fattore differenziale}\\
L'ipotesi che le derivate di f e g siano continue assicura che gli integrali siano ben definiti.
\subsection{Integrale indefinito, proprietà}
Dalle proprietà delle derivate si ottiene:
\begin{description}
	\item[I] \begin{equation*}
			\int[f(x)+g(x)]dx=\int f(x)dx+\int g(x)dx,
		\end{equation*}
	\item[II] \begin{equation*}
			\int cf(x)dx=c\int f(x)dx, c=costante
	\end{equation*}
\end{description}
\subsection{Integrale indefinito}
Integrali indefiniti immediati
\begin{multicols}{2}
	\begin{equation*}
		\int x^\alpha dx=\frac{x^{\alpha+1}}{\alpha+1}+x \alpha\neq -1
	\end{equation*}
	\begin{equation*}
		\int \frac{1}{x}dx=\ln|x|+c  \alpha=1
	\end{equation*}
	\begin{equation*}
		\int e^xdx=e^x+c
	\end{equation*}
	\begin{equation*}
		\int \sin x dx=-\cos x+c
	\end{equation*}
	\begin{equation*}
		\int \cos x dx=\sin x+c
	\end{equation*}
	\begin{equation*}
		\int\frac{1}{\cos^2x}dx=\tan x+c
	\end{equation*}
	\begin{equation*}
		\int \frac{1}{\sqrt{1-x^2}}dx=\arcsin x+c
	\end{equation*}
	\begin{equation*}
		\int \frac{-1}{\sqrt{1-x^2}}dx=\arccos x+c
	\end{equation*}
	\begin{equation*}
		\int \frac{1}{1+x^2}dx=\arctan x + c
	\end{equation*}
\end{multicols}
\subsection{Integrazione per sostituzione}
Sia F una primitiva di f in un intervallo I, ossia 
\begin{equation*}
	F^\prime (t)=f(t) \forall t\in I
\end{equation*}
Sia $t=g(x)$ una funzione derivabile con derivata continua in $[a,b]:g([a,b])\subset I$ del teorema della derivata di una funzione composta
\begin{equation*}
	D[F(g(x))]=F^\prime(g(x))+g^\prime(x)=f(g(x))*g^\prime(x)
\end{equation*}
Integrando otteniamo
\begin{equation*}
	\int D[F(g(x))]=\int f(g(x))*g^\prime(x)dx
\end{equation*}
Ovvero 
\begin{eqnarray*}
	\int f(g(x))*g^\prime(x)dx=F(g(x))+c
\end{eqnarray*}
Esercizio
\begin{equation*}
	\int \frac{\sin x}{\cos x}dx=-\int \frac{1}{\cos x}(-sin x)dx=-\ln |\cos x| +c 
\end{equation*}
\begin{itemize}
	\item \begin{equation*}
			\int \sin x \cos^2 x=-\int-\sin x \cos^2xdx=\frac{\cos^3 x}{3}+c
		\end{equation*}
	\item \begin{equation*}
			\int \frac{x}{\sqrt{1+x^2}}dx=(1+x^2)^\frac{1}{2}+c
		\end{equation*}
	\item \begin{equation*}
		\int \frac{1}{(1+x^2)\arctan x}dx=\int \frac{1}{(1+x^2)}\frac{1}{\arctan x}dx=\ln(\arctan x)+c
	\end{equation*}
\end{itemize}
\subsection{Integrazione per parti}
Siano f e g due funzioni derivabili con derivata comune, si ha
\begin{equation}
	\int f(x)g^\prime(x)dx=f(x)g(x)-\int f^\prime(x)g(x)dx
\end{equation}
\begin{enumerate}
	\item $f(x)$=fattore finito
	\item $g^\prime (x)dx$= fattore differenziale
\end{enumerate}
L'ipotesi che le derivate di f e g siano continue assicura che gli integrali siano ben definiti.
\subsubsection{Dimostrazione}
Consideriamo la formula di derivazione di un prodotto
\begin{equation*}
	[f(x)g(x)]^\prime=f^\prime (x)g(x)+f(x)g^\prime(x)
\end{equation*}
Integrando membro a membro si ha
\begin{equation*}
	\int [f(x)g(x)]^\prime dx=\int f^\prime g(x)dx+\int f g^\prime(x)dx
\end{equation*}
essendo $f*g$ una primitive della sua derivata $[f*g]^\prime$ si ottiene le tesi.
\paragraph{Esercizio}
\textit{Utilizzando il metodo di integrazione per parti calcolare}
\begin{itemize}
	\item $\int x\cos x dx=x\sin x-\int \sin xdx=x\sin x+\cos x +c$
	\item $\int \ln xdx=\int 1*\ln xdx=x\ln x-\int x*\frac{1}{x}dx=x\ln x+c$
	\item $\int e^x\sin xdx=\int e^x\sin x-\int e^x \cos xdx=e^x\sin x-(e^x \cos x+\int e^x \sin xdx) \Rightarrow \int e^x \sin xdx=\frac{e^x\cos x+\int e^x \sin xdx}{2}=\frac{e^x(\sin x-\cos x)}{2}+c$
	\item $\int \cos^2 xdx=\int \cos x*\cos xdx =\cos x \sin x + \int \sin^2 xdx=\cos x\sin x +x-\int \cos^2 xdx \Rightarrow\cos xdx=\frac{\cos x\sin x +x}{2}+c$
\end{itemize}
Se l'integrale è definito:
\begin{equation}
	\int^b_a f(x)dx
\end{equation}
e si effettua la sostituzione x=g(t). supponendo che
\begin{tasks}
	\task $x=a\Rightarrow c=g^{-1}(a)$
	\task $x=b\Rightarrow d=g^{-1}(b)$
\end{tasks}
si ha
\begin{equation*}
	\int^b_a f(x)dx=\int^d_c f(g(t))g^\prime(t)dt
\end{equation*}
Metodo di integrazione delle funzioni razionali fratte
\begin{equation*}
	\int \frac{N(x)}{D(x)}dx, N(x), D(x) \text{ polinomi di x}
\end{equation*}
\begin{description}
	\item[1°caso:] $grado(N(x))<grado(D(x))$
		\begin{tasks}
			\task D(x) ha radice \underline{radicale semplice}: si determinano le radici del denominatore $D(x)$ e lo si scompone in fattori\\
			Esercizio
			\begin{equation}
				\int\frac{1}{x^2-3x+2}
			\end{equation}
			$D(x)=x^2-3x+2=(x-2)(x-1)$\\
			Si devono cercare 2 costanti A e B (in quanto 2 sono i fattori semplici in cui è scomposto il polinomio D(x)):
			\begin{equation*}
				\frac{1}{x^2-3x+2}=\frac{A}{x-2}+\frac{B}{x-1}=\frac{(A+B)x-A2B}{(x-2)(x-1)}
			\end{equation*}
			Per il principio di identità dei polinomi, i polinomi a numeratore del 1° e dell'ultimo membro, sono uguali se sono uguali i rispettivi i rispettivi coefficienti cioè
			\begin{equation*}
				\begin{cases}
					A+B=0\\
					-A-2B=1
				\end{cases}\Rightarrow A=1\text{ }B=-1\Rightarrow \frac{1}{x^2-3x+2}-\frac{1}{x-1}
			\end{equation*}
			e quindi
			\begin{equation*}
				\int\frac{1}{x^2-3x+2}dx=\int\frac{1}{x-2}dx-\int \frac{1}{x-1}dx=\ln \bigg|\frac{x-2}{x-1}\bigg|+c
			\end{equation*}
			\task $D(x)$ ha radici \underline{reali multiple}\\
			Esercizio
			\begin{equation*}
				\int \frac{1}{x^3-x^2}dx
			\end{equation*}
			si ha $D(x)=x^3-x^2=x^2(x-1)$:\\
			una radice semplice (x=1) e una radice multipla di molteplicità (radice doppia x=0) si devono cercare 3 costanti:
			\begin{equation*}
				\Rightarrow \frac{1}{x^3-x^2}=\frac{A}{x}+\frac{B}{x^2}+\frac{C}{x-1}=\frac{Ax(x-1)+B(x-1)+Cx^2}{x^2(x-1)}
			\end{equation*}
			\begin{equation*}
				\Rightarrow \frac{1}{x^3-x^2}=\frac{(A+C)x^2+(-A+B)x-B}{x^2(x-1)}
			\end{equation*}
			\begin{equation*}
				\begin{cases}
					A+C=0&A=-1\\
					-A+B=0\Rightarrow&B=-1\\
					-B=1&C=1
				\end{cases}
			\end{equation*}
			\begin{equation*}
				\int \frac{1}{x^3-x^2}dx=-\int -\frac{1}{x}dx+\int-\frac{1}{x^2}dx+\int \frac{1}{x-1}dx=\ln\bigg|\frac{x-1}{x}\bigg|+\frac{1}{x}+c
			\end{equation*}
			\task $D(x)$ ha radici \textit{complesse coniugate e semplici}\\
				Esercizio
				\begin{equation*}
					\int \frac{1}{x^3+x^2+x+1}dx
				\end{equation*}
				\begin{equation*}
					D(x)=x^3+x^2+x+1=(x+1)(x^2+1)
				\end{equation*}
				3 radici: $x=-1$ reale semplice\\
				$x=\mp 1$ complesse coniugate
				\begin{equation*}
					\Rightarrow\frac{1}{x^3+x^2+x+1}=\frac{1}{(x+1)(x^2+1)}=\frac{A}{x+1}+\frac{Bx+C}{x^2+1}\Rightarrow
					 \begin{cases}
						A+B=0&a=\frac{1}{2}\\
						B+C=0\Rightarrow&B=-\frac{1}{2}\\
						A+C=1&C=\frac{1}{2}
					\end{cases}
				\end{equation*}
				E quindi si ottiene
				%\begin{equation*}
				%	\int \frac{1}{x^3+x^2+x+1}dx=\frac{1}{2}\int\frac{1}{x+1}dx-\frac{1}{2}\int\frac{x-1}{x^2+1}dx=\frac{1}{2}\int\frac{1}{x+1}dx-\frac{1}{4}\int\frac{2x}{x^2+1}dx+\frac{1}{2}\int\frac{2x}{x^2+1}dx
				%\end{equation*}
		\end{tasks} 
		\item [2° caso: ] grado(N(x)) grado(D(x))\\
		In questo caso si deve eseguire la deriv
		
\end{description}

\section{Integrali impropri o generalizzati}
In analisi matematica, l'integrale improprio o generalizzato è il limite di un integrale definito al tendere di un estremo di integrazione (o entrambi) ad un numero reale oppure all'infinito; tale numero reale può appartenere all'insieme di definizione della funzione integranda (\textit{e in tal caso si ottiene lo stesso risultato che si ha calcolando un integrale definito}), oppure può rappresentare un punto di discontinuità. Gli integrali impropri si utilizzano per rendere calcolabili integrali riguardanti intervalli illimitati e/o funzioni non limitate, che non sono trattabili con l'integrale di Riemann. Esso richiede infatti la limitatezza sia per l'intervallo di integrazione, sia per la funzione integranda.\\ By \href{https://it.wikipedia.org/wiki/Integrale_improprio}{Wikipedia}
